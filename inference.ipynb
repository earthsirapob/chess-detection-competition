{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oNhjPYgkcqj"
      },
      "source": [
        "# Chess Tracking System - Inference Pipeline\n",
        "**Final Project Submission**\n",
        "\n",
        "This notebook runs the full chess tracking pipeline on a set of test videos.  \n",
        "It loads the YOLO models, processes each video frame-by-frame, tracking moves, and generates a final `submission.csv` file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wR1Fpg92kcqk",
        "outputId": "ce983d43-33de-4570-90b3-4f25808ef5af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Downloading Videos...\n",
            "\n",
            "üì• Downloading Models...\n",
            "\n",
            "‚úÖ Setup Complete!\n"
          ]
        }
      ],
      "source": [
        "# Step 0: Download Dataset & Models\n",
        "# ==========================================\n",
        "import os\n",
        "import gdown\n",
        "\n",
        "# 1. Download Videos\n",
        "video_links = {\n",
        "    '2_Move_rotate_student.mp4': '1BCJ3jnNNToFxWFVQ_lHPxIrXArcIoSom',\n",
        "    '2_move_student.mp4': '1RGBWfPk9NSqq4KOmk7qDvKxawsxcOgH3',\n",
        "    '4_Move_studet.mp4': '1ANwwuHGFmTc5k3k1WEDEKAfmYkkYnrP3',\n",
        "    '6_Move_student.mp4': '1kUfrvkcLlbxSwlzooNyvdYkoWhT9dLmy',\n",
        "    '8_Move_student.mp4': '1Ka3IsuxC_y9RLIyLtcktUNz73jLivadV'\n",
        "}\n",
        "\n",
        "os.makedirs('test_videos', exist_ok=True)\n",
        "print(\"üì• Downloading Videos...\")\n",
        "for name, file_id in video_links.items():\n",
        "    if not os.path.exists(f'test_videos/{name}'):\n",
        "        gdown.download(f'https://drive.google.com/uc?id={file_id}', f'test_videos/{name}', quiet=True)\n",
        "\n",
        "# 2. Download Models (Directly from Folders)\n",
        "model_links = [\n",
        "    'https://drive.google.com/drive/folders/18W2Hee11FtioIxDCBs1GVm32dXtpw7aI?usp=drive_link', # chessboard-model\n",
        "    'https://drive.google.com/drive/folders/1oh1AydOSYQE7mnKnlYIUfqrg6zG2mix_?usp=drive_link'  # PIECE_MODEL_v8m\n",
        "]\n",
        "\n",
        "print(\"\\nüì• Downloading Models...\")\n",
        "for link in model_links:\n",
        "    gdown.download_folder(link, quiet=True, use_cookies=False)\n",
        "\n",
        "print(\"\\n‚úÖ Setup Complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q python-chess ultralytics opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HdfCXVuk3oR",
        "outputId": "66ae7fd1-63cd-4a2b-fd54-4d207ca75b77"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/6.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m222.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m126.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for chess (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "r_U4yJGVkcqk"
      },
      "outputs": [],
      "source": [
        "# 1. Setup & Imports\n",
        "import cv2\n",
        "import numpy as np\n",
        "import csv\n",
        "import chess\n",
        "import chess.pgn\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "from collections import deque, Counter\n",
        "from scipy.signal import find_peaks\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeXx0EGOkcqk",
        "outputId": "05f58fb3-61c3-4a98-df48-b25cead3c381"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è Using default video list (Check if Step 0 ran correctly).\n",
            "‚úÖ All model files found.\n"
          ]
        }
      ],
      "source": [
        "# 2. Configuration & Constants\n",
        "# ==========================================\n",
        "\n",
        "BOARD_MODEL_PATH = 'chessboard-model/weights/best.pt'\n",
        "PIECE_MODEL_PATH = 'PIECE_MODEL_v8m/weights/best.pt'\n",
        "\n",
        "# Set VIDEO_FILES to the ones we just confirmed/downloaded\n",
        "if 'valid_video_files' in globals() and valid_video_files:\n",
        "    VIDEO_FILES = valid_video_files\n",
        "    print(f\"üéØ Processing {len(VIDEO_FILES)} videos.\")\n",
        "else:\n",
        "    # Fallback default list\n",
        "    VIDEO_FILES = [\n",
        "        'test_videos/2_Move_rotate_student.mp4',\n",
        "        'test_videos/2_move_student.mp4',\n",
        "        'test_videos/4_Move_studet.mp4',\n",
        "        'test_videos/6_Move_student.mp4',\n",
        "        'test_videos/8_Move_student.mp4'\n",
        "    ]\n",
        "    print(\"‚ö†Ô∏è Using default video list (Check if Step 0 ran correctly).\")\n",
        "\n",
        "# Check if files exist to avoid runtime errors\n",
        "missing_files = []\n",
        "for p in [BOARD_MODEL_PATH, PIECE_MODEL_PATH]:\n",
        "    if not os.path.exists(p):\n",
        "        missing_files.append(p)\n",
        "\n",
        "if missing_files:\n",
        "    print(\"‚ö†Ô∏è WARNING: The following model files are missing:\")\n",
        "    for f in missing_files: print(f\"  - {f}\")\n",
        "else:\n",
        "    print(\"‚úÖ All model files found.\")\n",
        "\n",
        "STABILITY_THRESHOLD = 30\n",
        "\n",
        "CLASS_TO_FEN = {\n",
        "    0: 'b', 1: 'k', 2: 'n', 3: 'p', 4: 'q', 5: 'r',\n",
        "    6: 'B', 7: 'K', 8: 'N', 9: 'P', 10: 'Q', 11: 'R'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "lg4dQrGykcqk"
      },
      "outputs": [],
      "source": [
        "# 3. Helper Classes (Core Logic)\n",
        "# ==========================================\n",
        "\n",
        "class BoardStabilizer:\n",
        "    def __init__(self, alpha=0.2, max_dist=50):\n",
        "        self.prev_points = None; self.alpha = alpha; self.max_dist = max_dist\n",
        "    def update(self, current_points):\n",
        "        if self.prev_points is None: self.prev_points = current_points; return current_points\n",
        "        dist = np.linalg.norm(current_points - self.prev_points)\n",
        "        if dist > self.max_dist: return self.prev_points\n",
        "        smoothed = (current_points * self.alpha) + (self.prev_points * (1 - self.alpha))\n",
        "        self.prev_points = smoothed\n",
        "        return smoothed\n",
        "\n",
        "class GridProjectionCalibrator:\n",
        "    def __init__(self):\n",
        "        self.accumulated_edges_v = None; self.accumulated_edges_h = None\n",
        "        self.frame_count = 0; self.is_calibrated = False\n",
        "        self.grid_params = (20, 20, 75, 75)\n",
        "    def add_frame(self, warped_image):\n",
        "        gray = cv2.cvtColor(warped_image, cv2.COLOR_BGR2GRAY)\n",
        "        sob_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
        "        sob_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
        "        if self.accumulated_edges_v is None:\n",
        "            self.accumulated_edges_v = cv2.convertScaleAbs(sob_x).astype(\"float32\")\n",
        "            self.accumulated_edges_h = cv2.convertScaleAbs(sob_y).astype(\"float32\")\n",
        "        else:\n",
        "            cv2.accumulateWeighted(cv2.convertScaleAbs(sob_x).astype(\"float32\"), self.accumulated_edges_v, 0.1)\n",
        "            cv2.accumulateWeighted(cv2.convertScaleAbs(sob_y).astype(\"float32\"), self.accumulated_edges_h, 0.1)\n",
        "        self.frame_count += 1\n",
        "    def compute_grid(self):\n",
        "        if self.frame_count < 10: return self.fallback_grid(640, 640)\n",
        "        proj_x = np.sum(self.accumulated_edges_v, axis=0)\n",
        "        proj_y = np.sum(self.accumulated_edges_h, axis=1)\n",
        "        peaks_x, _ = find_peaks(cv2.normalize(proj_x, None, 0, 255, cv2.NORM_MINMAX).flatten(), height=40, distance=40)\n",
        "        peaks_y, _ = find_peaks(cv2.normalize(proj_y, None, 0, 255, cv2.NORM_MINMAX).flatten(), height=40, distance=40)\n",
        "        if len(peaks_x) < 7 or len(peaks_y) < 7: return self.fallback_grid(640, 640)\n",
        "        start_x, end_x = peaks_x[0], peaks_x[-1]\n",
        "        start_y, end_y = peaks_y[0], peaks_y[-1]\n",
        "        self.grid_params = (start_x, start_y, (end_x - start_x)/8.0, (end_y - start_y)/8.0)\n",
        "        self.is_calibrated = True; return True\n",
        "    def fallback_grid(self, w, h):\n",
        "        margin = w * 0.04; cell = (w - 2*margin) / 8.0\n",
        "        self.grid_params = (margin, margin, cell, cell)\n",
        "        self.is_calibrated = True; return True\n",
        "\n",
        "class ChessGameTracker:\n",
        "    def __init__(self):\n",
        "        self.board = None; self.pgn_moves = []\n",
        "        self.grid_buffer = deque(maxlen=15)\n",
        "        self.last_stable_fen = None; self.candidate_fen = None; self.stability_counter = 0\n",
        "        self.black_started = False\n",
        "\n",
        "    def board_to_fen_part(self, board_grid):\n",
        "        fen_rows = []\n",
        "        for row in range(8):\n",
        "            empty = 0; fen = \"\"\n",
        "            for col in range(8):\n",
        "                piece = board_grid[row][col]\n",
        "                if piece == '': empty += 1\n",
        "                else:\n",
        "                    if empty > 0: fen += str(empty); empty = 0\n",
        "                    fen += piece\n",
        "            if empty > 0: fen += str(empty)\n",
        "            fen_rows.append(fen)\n",
        "        return \"/\".join(fen_rows)\n",
        "\n",
        "    def update(self, current_grid):\n",
        "        simple_grid = [['' for _ in range(8)] for _ in range(8)]\n",
        "        for r in range(8):\n",
        "            for c in range(8):\n",
        "                if current_grid[r][c]: simple_grid[r][c] = current_grid[r][c]['fen']\n",
        "        self.grid_buffer.append(simple_grid)\n",
        "        if len(self.grid_buffer) < 5: return None\n",
        "        stable_grid = [['' for _ in range(8)] for _ in range(8)]\n",
        "        for r in range(8):\n",
        "            for c in range(8):\n",
        "                candidates = [grid[r][c] for grid in self.grid_buffer]\n",
        "                from collections import Counter\n",
        "                most_common, count = Counter(candidates).most_common(1)[0]\n",
        "                if count >= len(self.grid_buffer) * 0.6: stable_grid[r][c] = most_common\n",
        "                else: return None\n",
        "\n",
        "        detected_fen = self.board_to_fen_part(stable_grid)\n",
        "        if self.board is None:\n",
        "            # print(f\"[INIT] Start Position: {detected_fen}\")\n",
        "            self.board = chess.Board(detected_fen + \" w KQkq - 0 1\")\n",
        "            self.last_stable_fen = detected_fen\n",
        "            return None\n",
        "\n",
        "        if detected_fen == self.last_stable_fen:\n",
        "            self.stability_counter = 0; self.candidate_fen = None; return None\n",
        "        if detected_fen == self.candidate_fen: self.stability_counter += 1\n",
        "        else: self.candidate_fen = detected_fen; self.stability_counter = 0\n",
        "\n",
        "        if self.stability_counter >= STABILITY_THRESHOLD:\n",
        "            move_san = self.validate_and_push_move(self.candidate_fen)\n",
        "            if move_san: self.last_stable_fen = self.candidate_fen\n",
        "            self.stability_counter = 0; self.candidate_fen = None\n",
        "            return move_san\n",
        "        return None\n",
        "\n",
        "    def validate_and_push_move(self, target_fen_part):\n",
        "        target_dict = self.fen_to_dict(target_fen_part)\n",
        "        candidates = []\n",
        "        turns_to_check = [self.board.turn, not self.board.turn]\n",
        "        for turn in turns_to_check:\n",
        "            original_turn = self.board.turn\n",
        "            self.board.turn = turn\n",
        "            for move in self.board.legal_moves:\n",
        "                move_san = self.board.san(move)\n",
        "                from_sq, to_sq = move.from_square, move.to_square\n",
        "                # Map using \"White Top\" Logic (Standard for your setup)\n",
        "                src_r, src_c = 7 - (from_sq // 8), from_sq % 8\n",
        "                dst_r, dest_c = 7 - (to_sq // 8), to_sq % 8\n",
        "\n",
        "                moving_piece = self.board.piece_at(from_sq).symbol()\n",
        "                detected_at_src = target_dict.get((src_r, src_c))\n",
        "                detected_at_dest = target_dict.get((dst_r, dest_c))\n",
        "\n",
        "                score = 0\n",
        "                if detected_at_dest == moving_piece: score += 20\n",
        "                elif detected_at_dest is not None: score += 5\n",
        "                else: score -= 50\n",
        "                if detected_at_src is None: score += 20\n",
        "                else: score -= 20\n",
        "                if score > 0: candidates.append({'move': move, 'san': move_san, 'score': score, 'turn': turn})\n",
        "            self.board.turn = original_turn\n",
        "\n",
        "        if not candidates: return None\n",
        "        best = sorted(candidates, key=lambda x: x['score'], reverse=True)[0]\n",
        "        if best['score'] >= 30:\n",
        "            if len(self.pgn_moves) == 0 and best['turn'] == chess.BLACK:\n",
        "                # print(\"‚ö´ DETECTED: Black moves first!\")\n",
        "                self.black_started = True\n",
        "            if best['turn'] != self.board.turn: self.board.turn = best['turn']\n",
        "            self.board.push(best['move'])\n",
        "            self.pgn_moves.append(best['san'])\n",
        "            print(f\"  üöÄ Move: {best['san']}\")\n",
        "            return best['san']\n",
        "        return None\n",
        "\n",
        "    def fen_to_dict(self, fen_str):\n",
        "        m = {}; rows = fen_str.split('/')\n",
        "        for r, row in enumerate(rows):\n",
        "            c = 0\n",
        "            for char in row:\n",
        "                if char.isdigit(): c += int(char)\n",
        "                else: m[(r,c)] = char; c += 1\n",
        "        return m\n",
        "\n",
        "    def get_pgn_string(self):\n",
        "        # Returns PGN moves spread in a single line string format\n",
        "        pgn_str = \"\"; idx, move_num = 0, 1\n",
        "        if self.black_started:\n",
        "            if idx < len(self.pgn_moves):\n",
        "                pgn_str += f\"1... {self.pgn_moves[idx]} \"; idx += 1; move_num = 2\n",
        "        while idx < len(self.pgn_moves):\n",
        "            pgn_str += f\"{move_num}. {self.pgn_moves[idx]} \"; idx += 1\n",
        "            if idx < len(self.pgn_moves): pgn_str += f\"{self.pgn_moves[idx]} \"; idx += 1\n",
        "            move_num += 1\n",
        "        return pgn_str.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "D3b6dRI_kcql"
      },
      "outputs": [],
      "source": [
        "# 4. Geometry & Detection Functions\n",
        "# ==========================================\n",
        "\n",
        "def order_points(pts):\n",
        "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
        "    s = pts.sum(axis=1)\n",
        "    rect[0], rect[2] = pts[np.argmin(s)], pts[np.argmax(s)]\n",
        "    diff = np.diff(pts, axis=1)\n",
        "    rect[1], rect[3] = pts[np.argmin(diff)], pts[np.argmax(diff)]\n",
        "    return rect\n",
        "\n",
        "def warp_chessboard(image, board_model, fixed_M=None, stabilizer=None):\n",
        "    if fixed_M is not None: return cv2.warpPerspective(image, fixed_M, (640, 640)), fixed_M\n",
        "    results = board_model(image, verbose=False)\n",
        "    if not results[0].masks: return None, None\n",
        "    mask = cv2.resize(results[0].masks.data[0].cpu().numpy().astype(np.uint8), (image.shape[1], image.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if not contours: return None, None\n",
        "    largest = max(contours, key=cv2.contourArea)\n",
        "    approx = cv2.approxPolyDP(largest, 0.04 * cv2.arcLength(largest, True), True)\n",
        "    if len(approx) != 4: approx = cv2.boxPoints(cv2.minAreaRect(largest))\n",
        "    src_pts = order_points(approx.reshape(4, 2).astype(\"float32\"))\n",
        "    if stabilizer: src_pts = stabilizer.update(src_pts)\n",
        "    M = cv2.getPerspectiveTransform(src_pts, np.array([[0,0],[639,0],[639,639],[0,639]], dtype=\"float32\"))\n",
        "    return cv2.warpPerspective(image, M, (640, 640)), M\n",
        "\n",
        "def fix_board_orientation(image, piece_model):\n",
        "    results = piece_model(image, conf=0.3, verbose=False)\n",
        "    wx, wy = [], []\n",
        "    h, w = image.shape[:2]\n",
        "\n",
        "    for box in results[0].boxes:\n",
        "        cls_id = int(box.cls[0].item())\n",
        "        if cls_id in CLASS_TO_FEN and CLASS_TO_FEN[cls_id].isupper():\n",
        "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "            wx.append((x1 + x2)/2)\n",
        "            wy.append((y1 + y2)/2)\n",
        "\n",
        "    if len(wx) < 3: return image, \"Unknown\"\n",
        "\n",
        "    avg_x = np.mean(wx) / w\n",
        "    avg_y = np.mean(wy) / h\n",
        "\n",
        "    # Force \"White on TOP\"\n",
        "    dist_top = (avg_x - 0.5)**2 + (avg_y - 0.15)**2\n",
        "    dist_bottom = (avg_x - 0.5)**2 + (avg_y - 0.85)**2\n",
        "    dist_left = (avg_x - 0.15)**2 + (avg_y - 0.5)**2\n",
        "    dist_right = (avg_x - 0.85)**2 + (avg_y - 0.5)**2\n",
        "\n",
        "    min_dist = min(dist_top, dist_bottom, dist_left, dist_right)\n",
        "\n",
        "    if min_dist == dist_top: return image, \"Top (Correct)\"\n",
        "    elif min_dist == dist_bottom: return cv2.rotate(image, cv2.ROTATE_180), \"Bottom -> Rotated 180\"\n",
        "    elif min_dist == dist_left: return cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE), \"Left -> Rotated CW\"\n",
        "    elif min_dist == dist_right: return cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE), \"Right -> Rotated CCW\"\n",
        "\n",
        "    return image, \"Ambiguous\"\n",
        "\n",
        "def generate_grid_auto(warped_image, piece_model, grid_params):\n",
        "    results = piece_model(warped_image, conf=0.5, verbose=False)\n",
        "    start_x, start_y, cell_w, cell_h = grid_params\n",
        "    board_grid = [[None for _ in range(8)] for _ in range(8)]\n",
        "\n",
        "    for box in results[0].boxes:\n",
        "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "        cls_id = int(box.cls[0].item())\n",
        "        if cls_id not in CLASS_TO_FEN: continue\n",
        "\n",
        "        anchor_x = (x1 + x2) / 2\n",
        "        anchor_y = y2 - ((y2 - y1) * 0.10)\n",
        "\n",
        "        col_idx = int((anchor_x - start_x) // cell_w)\n",
        "        row_idx = int((anchor_y - start_y) // cell_h)\n",
        "\n",
        "        if 0 <= col_idx < 8 and 0 <= row_idx < 8:\n",
        "            final_r, final_c = 7 - row_idx, 7 - col_idx\n",
        "            curr = board_grid[final_r][final_c]\n",
        "            if curr is None or float(box.conf[0]) > curr['conf']:\n",
        "                board_grid[final_r][final_c] = {'fen': CLASS_TO_FEN[cls_id], 'conf': float(box.conf[0])}\n",
        "    return board_grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3oUJ2ikCkcql"
      },
      "outputs": [],
      "source": [
        "# 5. Main Processing Function\n",
        "# ==========================================\n",
        "\n",
        "def process_video(video_path, start_sec=0):\n",
        "    if not os.path.exists(video_path):\n",
        "        print(f\"‚ùå File Not Found: {video_path}\")\n",
        "        return \"\"\n",
        "\n",
        "    print(f\"\\n‚è≥ Processing: {video_path}...\")\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    start_frame_idx = int(start_sec * fps)\n",
        "    if start_frame_idx > 0: cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame_idx)\n",
        "\n",
        "    # Initialize Per-Video States\n",
        "    tracker = ChessGameTracker()\n",
        "    calibrator = GridProjectionCalibrator()\n",
        "    stabilizer = BoardStabilizer()\n",
        "\n",
        "    fixed_M = None\n",
        "    calibrated = False\n",
        "    locked_rotation = None\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret: break\n",
        "\n",
        "        # Warp Board\n",
        "        warped_img, M = warp_chessboard(frame, board_model, fixed_M=fixed_M, stabilizer=stabilizer)\n",
        "\n",
        "        if warped_img is not None:\n",
        "            frame_idx = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
        "            if not calibrated:\n",
        "                rotated_img, status = fix_board_orientation(warped_img, piece_model)\n",
        "                calibrator.add_frame(rotated_img)\n",
        "                if frame_idx >= (start_frame_idx + 45):\n",
        "                    success = calibrator.compute_grid()\n",
        "                    fixed_M = M\n",
        "                    calibrated = True\n",
        "                    if \"180\" in status: locked_rotation = cv2.ROTATE_180\n",
        "                    elif \"CCW\" in status: locked_rotation = cv2.ROTATE_90_COUNTERCLOCKWISE\n",
        "                    elif \"CW\" in status: locked_rotation = cv2.ROTATE_90_CLOCKWISE\n",
        "                    else: locked_rotation = None\n",
        "                    # print(f\"  üîí Calibrated. Mode: {status}\")\n",
        "            else:\n",
        "                final_img = warped_img\n",
        "                if locked_rotation is not None:\n",
        "                    final_img = cv2.rotate(warped_img, locked_rotation)\n",
        "\n",
        "                # Detect Pieces & Update Game State\n",
        "                board_grid = generate_grid_auto(final_img, piece_model, calibrator.grid_params)\n",
        "                tracker.update(board_grid)\n",
        "\n",
        "    cap.release()\n",
        "    final_pgn = tracker.get_pgn_string()\n",
        "    print(f\"‚úÖ Finished. Moves: {len(tracker.pgn_moves)}\")\n",
        "    return final_pgn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "qRMCpfCUkcql",
        "outputId": "65b9ad41-6058-4399-c93f-9d43f5be0cc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≥ Loading Models...\n",
            "\n",
            "‚è≥ Processing: test_videos/2_Move_rotate_student.mp4...\n",
            "  üöÄ Move: Qh4+\n",
            "  üöÄ Move: g3\n",
            "‚úÖ Finished. Moves: 2\n",
            "\n",
            "‚è≥ Processing: test_videos/2_move_student.mp4...\n",
            "  üöÄ Move: Qh4+\n",
            "  üöÄ Move: g3\n",
            "‚úÖ Finished. Moves: 2\n",
            "\n",
            "‚è≥ Processing: test_videos/4_Move_studet.mp4...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1490747027.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Run Inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mpgn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Collect Result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3282403255.py\u001b[0m in \u001b[0;36mprocess_video\u001b[0;34m(video_path, start_sec)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;31m# Detect Pieces & Update Game State\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mboard_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_grid_auto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpiece_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalibrator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                 \u001b[0mtracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3249769754.py\u001b[0m in \u001b[0;36mgenerate_grid_auto\u001b[0;34m(warped_image, piece_model, grid_params)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_grid_auto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarped_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpiece_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpiece_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarped_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mstart_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mboard_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;34m...\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Detected {len(r)} objects in image\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \"\"\"\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprompts\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"set_prompts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for SAM-type models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_cli\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     def track(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# merge list of Result into one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mgenerator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m# Issuing `None` to a generator fires it up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36mstream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0;31m# Postprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mprofilers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim0s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_predict_postprocess_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/models/yolo/detect/predict.py\u001b[0m in \u001b[0;36mpostprocess\u001b[0;34m(self, preds, img, orig_imgs, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \"\"\"\n\u001b[1;32m     53\u001b[0m         \u001b[0msave_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_feats\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         preds = nms.non_max_suppression(\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/utils/nms.py\u001b[0m in \u001b[0;36mnon_max_suppression\u001b[0;34m(prediction, conf_thres, iou_thres, classes, agnostic, multi_label, labels, max_det, nc, max_time_img, max_nms, max_wh, rotated, end2end, return_idxs)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_thres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTorchNMS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_thres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmax_det\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# limit detections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/utils/nms.py\u001b[0m in \u001b[0;36mnms\u001b[0;34m(boxes, scores, iou_threshold)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mkeep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mkeep_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0;32mwhile\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0mkeep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeep_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 6. Execution Loop (Batch Processing)\n",
        "# ==========================================\n",
        "\n",
        "print(\"‚è≥ Loading Models...\")\n",
        "if os.path.exists(BOARD_MODEL_PATH) and os.path.exists(PIECE_MODEL_PATH):\n",
        "    board_model = YOLO(BOARD_MODEL_PATH)\n",
        "    piece_model = YOLO(PIECE_MODEL_PATH)\n",
        "\n",
        "    dataset_results = []\n",
        "\n",
        "    for video_file in VIDEO_FILES:\n",
        "        # Extract simple filename for row_id\n",
        "        row_id = os.path.basename(video_file)\n",
        "\n",
        "        # Run Inference\n",
        "        pgn_output = process_video(video_file)\n",
        "\n",
        "        # Collect Result\n",
        "        dataset_results.append({\"row_id\": row_id, \"output\": pgn_output})\n",
        "\n",
        "    print(\"\\nüéâ All videos processed.\")\n",
        "else:\n",
        "    print(\"‚ùå Models not found. Cannot proceed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjqPlmiKkcql",
        "outputId": "dbad3fb6-77d6-4023-8ae6-2276241a1996"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Saving submission.csv...\n",
            "‚úÖ CSV Saved Successfully.\n",
            "\n",
            "--- Preview ---\n",
            "2_Move_rotate_student.mp4: 1... Qh4+ 2. g3...\n",
            "2_move_student.mp4: 1... Qh4+ 2. g3...\n"
          ]
        }
      ],
      "source": [
        "# 7. Save Submission CSV\n",
        "# ==========================================\n",
        "\n",
        "OUTPUT_CSV = \"submission.csv\"\n",
        "\n",
        "if dataset_results:\n",
        "    print(f\"üíæ Saving {OUTPUT_CSV}...\")\n",
        "    with open(OUTPUT_CSV, mode='w', newline='', encoding='utf-8') as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=[\"row_id\", \"output\"])\n",
        "        writer.writeheader()\n",
        "        writer.writerows(dataset_results)\n",
        "    print(\"‚úÖ CSV Saved Successfully.\")\n",
        "\n",
        "    # Preview top 5 rows\n",
        "    print(\"\\n--- Preview ---\")\n",
        "    for r in dataset_results[:5]:\n",
        "        print(f\"{r['row_id']}: {r['output'][:50]}...\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}